---
title: "Models"
author: "PLSC 31101"
date: "Fall 2020"
output: html_document
---

## Inferences and Regressions

Once we have imported our data, summarized it, carried out group-wise operations, and perhaps reshaped it, we may also want to attempt causal inference.

This often requires doing the following:

1) Carrying out hypothesis tests
2) Estimating regression models

```{r}
# Setup
library(gapminder)
library(tidyverse)
library(broom)

# read gapminder
gap <- gapminder
```

### Statistical Tests

Let's say we are interested in whether the life expectancy in 1967 is different than in 1977.

NB: `pull()` is a `dplyr` method to select a single variable as store it as a 1d vector.

```{r message=F}
# Pull out life expectancy by different years
lifeExp_1967 <- gap %>% 
  filter(year==1967) %>%
  pull(lifeExp)

lifeExp_1977 <- gap %>% 
  filter(year==1977) %>%
  pull(lifeExp)
```

One can test for differences in distributions in either:

1) Their means using t-tests:
```{r warning=F}
# t test of means
t.test(x = lifeExp_1967, y = lifeExp_1977)
```

2) Their entire distributions using ks-tests:
```{r warning=F}
# ks tests of distributions
ks.test(x = lifeExp_1967, y = lifeExp_1977)
```

### Regressions and Linear Models

Running regressions in R is generally straightforward. There are two basic, catch-all regression functions in R:

- `lm` fits a standard linear regression with OLS (equivalent to `glm` with `family = gaussian(link = "identity")`).

- `glm` fits a generalized linear model with your choice of family/link function.

There are a bunch of families and links to use (`?family` for a full list), but some essentials are: 

* `binomial(link = "logit")`, 
* `gaussian(link = "identity")`
* `poisson(link = "log")`.

#### Formulas {-}

We specify the statistical relationships to fit using a *formula*. The variable on the left-hand side of a tilde (`~`) is called the "dependent variable", while the variables on the right-hand side are called the "independent variables" and are joined by plus signs `+` (for a basic linear combination).

Example: Suppose we want to regress life expectancy on GDP per capita and population, as well as continent and year.  

The `lm` call looks something like this:

```{r}
mod <- lm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent + year, 
          data = gap)
```

The `glm` call would look something like this:

```{r eval=FALSE}
mod <- glm(formula = lifeExp ~ log(gdpPercap) + log(pop) + continent + year,
           data = gap, 
           family = gaussian(link = "identity"))
```

In addition to the `+` symbol, there are also other operators to control your formulas:

`-` for removing terms;
`:` for interaction;
`*` for crossing;
`.` for all other variables in the dataframe that haven't yet been included in the model.

Let's see some of these in action:

```{r}
# `.` includes all  variables but `-` removes specific terms:
mod.1 <- lm(lifeExp ~ . - country,
            data = gap)
summary(mod.1)

# `x1:x2` interacts all terms in `x1` with all terms in `x2`:
mod.2 <- lm(lifeExp ~ log(gdpPercap) + log(pop) + continent:factor(year), 
            data = gap)
summary(mod.2)

# `x1*x2` produces the cross of `x1` and `x2`, or `x1 + x2 + x1:x2`:
mod.3 <- lm(lifeExp ~ log(gdpPercap) + log(pop) + continent*factor(year), 
            data = gap)
summary(mod.3)

```

#### Categorical variables (Factors) {-}

Note that we wrapped the `year` variable into a `factor()` function. By default, R breaks up our variables into their different factor levels (as it will do whenever your regressors have factor levels).

If your data are not factorized, you can tell `lm/glm` to factorize a variable (i.e., create dummy variables on the fly) by writing `factor()`.

#### Missing values {-}

Missing values obviously cannot convey any information about the relationship between the variables. Most modeling functions will drop any rows that contain missing values.

### Regression Output

When we store this regression in an object, we get access to several items of interest.

First, R has a helpful `summary` method for regression objects:

```{r}
summary(mod)
```

We can also extract specific information from the model object itself:

1. All components contained in the regression output:

```{r}
names(mod)
```

2. Regression coefficients:

```{r}
mod$coefficients
```

3. Regression degrees of freedom:

```{r}
mod$df.residual
```

4. Standard (diagnostic) plots for a regression:

```{r}
plot(mod)
```

### Tidying model data with `broom`

The `broom` package, by David Robinson, turn models into tidy data. 
`broom::tidy(model)` returns a row for each coefficient in the model. Each column gives information about the estimate or its variability.

```{r}
mod_tidy <- tidy(mod)
mod_tidy
```

This is a powerful technique for working with large numbers of models because once you have tidy data, you can apply all of the techniques that youâ€™ve learned about earlier in the book.

### Formatting Regression Tables

Most papers report the results of regression analysis in some kind of table. Typically, this table includes the values of coefficients, standard errors, and significance levels from one or more models. 

The `stargazer` package provides excellent tools to make and format regression tables automatically. It can also output summary statistics from a dataframe.

```{r}
library(stargazer)
stargazer(gap, type = "text")
```

Let's say we want to report the results from three different models:

```{r}
mod.1 <- lm(lifeExp ~ log(gdpPercap) + log(pop), data = gap)
mod.2 <- lm(lifeExp ~ log(gdpPercap) + log(pop) + continent, data = gap)
mod.3 <- lm(lifeExp ~ log(gdpPercap) + log(pop) + continent + year, data = gap)
```

`stargazer` can produce well-formatted tables that hold regression analysis results from all these models side-by-side.

```{r}
stargazer(mod.1, mod.2, mod.3, title = "Regression Results", type = "text")
```

#### Customization {-}

`stargazer` is incredibly customizable. Let's say we wanted to

- Re-name our explanatory variables;
- Remove information on the "Constant";
- Only keep the number of observations from the summary statistics; and
- Style the table to look like those in the American Journal of Political Science.

```{r}
stargazer(mod.1, mod.2, mod.3, title = "Regression Results", type = "text", 
          covariate.labels	= c("GDP per capita, logged", "Population, logged", "Americas", "Asia", "Europe", "Oceania", "Year", "Constant"), 
          omit = "Constant", 
          keep.stat="n", style = "ajps")
```

Check out `?stargazer` to see more options.

#### Output Types {-}

Once we like the look of our table, we can output/export it in a number of ways. The `type` argument specifies what output the command should produce. Possible values are:

- `"latex"` for LaTeX code.
- `"html"` for HTML code.
- `"text"` for ASCII text output (what we used above).

Let's say we are using LaTeX to typeset our paper. We can output our regression table in LaTeX:

```{r}
stargazer(mod.1, mod.2, mod.3, title = "Regression Results", type = "latex", 
          covariate.labels	= c("GDP per capita, logged", "Population, logged", "Americas", "Asia", "Europe", "Oceania", "Year", "Constant"), 
          omit = "Constant", 
          keep.stat="n", style = "ajps")
```


To include the produced tables in our paper, we can simply insert this `stargazer` LaTeX output into the publication's TeX source. 

Alternatively, you can use the `out` argument to save the output in a .tex or .txt file:

```{r eval = F}
stargazer(mod.1, mod.2, mod.3, title = "Regression Results", type = "latex", 
          covariate.labels	= c("GDP per capita, logged", "Population, logged", "Americas", "Asia", "Europe", "Oceania", "Year", "Constant"), 
          omit = "Constant", 
          keep.stat="n", style = "ajps",
          out = "regression-table.txt")
```

To include `stargazer` tables in Microsoft Word documents (e.g., .doc or .docx), use the following procedure:

- Use the `out` argument to save output into an `.html` file.
- Open the resulting file in your web browser.
- Copy and paste the table from the web browser to your Microsoft Word document.

```{r eval = F}
stargazer(mod.1, mod.2, mod.3, title = "Regression Results", type = "html", 
          covariate.labels	= c("GDP per capita, logged", "Population, logged", "Americas", "Asia", "Europe", "Oceania", "Year", "Constant"), 
          omit = "Constant", 
          keep.stat="n", style = "ajps",
          out = "regression-table.html")
```

### Challenges

#### Challenge 1. {-}

Fit two linear regression models from the `gapminder` data where the outcome is `lifeExp` and the explanatory variables are `log(pop)`, `log(gdpPercap)`, and `year`. In one model, treat `year` as a numeric variable. In the other, factorize the `year` variable. How do you interpret each model?

#### Challenge 2. {-}

Fit a logistic regression model where the outcome is whether `lifeExp` is greater than or less than 60 years, exploring the use of different predictors.

#### Challenge 3. {-}

Using `stargazer`, format a table reporting the results from the three models you created above (two linear regressions and one logistic).

#### Challenge 4 {-}

Check out the program below. For each line of code, write a comment describing what it does.

NB: You might some see some code we haven't yet covered in class. Try to guess what it does anyway.

```{r eval = F}
mod <- lm(lifeExp ~ country + year + log(pop) + log(gdpPercap), data = gap)

mod_df <- tidy(mod) %>%
  slice(2:142) %>%
  separate(term, into = c("term", "country"), sep = "country") %>%
  select(country, estimate, std.error)
  
mod_df <- mod_df %>%
  mutate(low = estimate - qnorm((1-0.95)/2)*(std.error),
         hi = estimate + qnorm((1-0.95)/2)*(std.error))

ggplot(mod_df, aes(x =  fct_reorder(country, estimate),
                   y = estimate, 
                   ymin = low, 
                   ymax = hi)) +
  geom_pointrange(colour = "red", size = .2) +
  ylab("Marginal Effect on Life Expectancy") +
  xlab("Country") +
  coord_flip() +
  theme(axis.text.y = element_text(size = 5))
```
        
      

